{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d95f841a-63c9-41d4-aea1-496b3d2024dd",
   "metadata": {},
   "source": [
    "**LLM Workshop 2024 by Sebastian Raschka**\n",
    "\n",
    "This code is based on *Build a Large Language Model (From Scratch)*, [https://github.com/rasbt/LLMs-from-scratch](https://github.com/rasbt/LLMs-from-scratch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aa40e3-5109-433f-9153-f5770531fe94",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# 2) Understanding LLM Input Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d5d2c0-cba8-404e-9bf3-71a218cae3cf",
   "metadata": {},
   "source": [
    "Packages that are being used in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d1305cf-12d5-46fe-a2c9-36fb71c5b3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.7.0\n",
      "tiktoken version: 0.7.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "\n",
    "print(\"torch version:\", version(\"torch\"))\n",
    "print(\"tiktoken version:\", version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a42fbfd-e3c2-43c2-bc12-f5f870a0b10a",
   "metadata": {},
   "source": [
    "- This notebook provides a brief overview of the data preparation and sampling procedures to get input data \"ready\" for an LLM\n",
    "- Understanding what the input data looks like is a great first step towards understanding how LLMs work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628b2922-594d-4ff9-bd82-04f1ebdf41f5",
   "metadata": {},
   "source": [
    "<img src=\"./figures/01.png\" width=\"1000px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddbb984-8d23-40c5-bbfa-c3c379e7eec3",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# 2.1 Tokenizing text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c90731-7dc9-4cd3-8c4a-488e33b48e80",
   "metadata": {},
   "source": [
    "- In this section, we tokenize text, which means breaking text into smaller units, such as individual words and punctuation characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09872fdb-9d4e-40c4-949d-52a01a43ec4b",
   "metadata": {},
   "source": [
    "<img src=\"figures/02.png\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cceaa18-833d-46b6-b211-b20c53902805",
   "metadata": {},
   "source": [
    "- Load raw text we want to work with\n",
    "- [The Verdict by Edith Wharton](https://en.wikisource.org/wiki/The_Verdict) is a public domain short story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a769e87-470a-48b9-8bdb-12841b416198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of character: 20479\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "    \n",
    "print(\"Total number of character:\", len(raw_text))\n",
    "print(raw_text[:99])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b971a46-ac03-4368-88ae-3f20279e8f4e",
   "metadata": {},
   "source": [
    "- The goal is to tokenize and embed this text for an LLM\n",
    "- Let's develop a simple tokenizer based on some simple sample text that we can then later apply to the text above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbe9330-b587-4262-be9f-497a84ec0e8a",
   "metadata": {},
   "source": [
    "<img src=\"figures/03.png\" width=\"690px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daa1687-2c08-485a-87cc-a93c2f9586d7",
   "metadata": {},
   "source": [
    "- The following regular expression will split on whitespaces and punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "737dd5b0-9dbb-4a97-9ae4-3482c8c04be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', ' ', 'HAD', ' ', 'always', ' ', 'thought', ' ', 'Jack', ' ', 'Gisburn', ' ', 'rather', ' ', 'a', ' ', 'cheap', ' ', 'genius', '--', 'though', ' ', 'a', ' ', 'good', ' ', 'fellow', ' ', 'enough', '--', 'so', ' ', 'it', ' ', 'was', ' ', 'no', ' ']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed = [item for item in preprocessed if item]\n",
    "print(preprocessed[:38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35db7b5e-510b-4c45-995f-f5ad64a8e19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 8405\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of tokens:\", len(preprocessed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5ce8fe-3a07-4f2a-90f1-a0321ce3a231",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# 2.2 Converting tokens into token IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5204973-f414-4c0d-87b0-cfec1f06e6ff",
   "metadata": {},
   "source": [
    "- Next, we convert the text tokens into token IDs that we can process via embedding layers later\n",
    "- For this we first need to build a vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177b041d-f739-43b8-bd81-0443ae3a7f8d",
   "metadata": {},
   "source": [
    "<img src=\"figures/04.png\" width=\"900px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeade64-037b-4b59-9039-d3b000ef8886",
   "metadata": {},
   "source": [
    "- The vocabulary contains the unique words in the input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fdf0533-5ab6-42a5-83fa-a3b045de6396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1132\n"
     ]
    }
   ],
   "source": [
    "all_words = sorted(set(preprocessed))\n",
    "vocab_size = len(all_words)\n",
    "\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77d00d96-881f-4691-bb03-84fec2a75a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {token:integer for integer,token in enumerate(all_words)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bd1f81-3a8f-4dd9-9dd6-e75f32dacbe3",
   "metadata": {},
   "source": [
    "- Below are the first 50 entries in this vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1c5de4a-aa4e-4aec-b532-10bb364039d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n', 0)\n",
      "(' ', 1)\n",
      "('!', 2)\n",
      "('\"', 3)\n",
      "(\"'\", 4)\n",
      "('(', 5)\n",
      "(')', 6)\n",
      "(',', 7)\n",
      "('--', 8)\n",
      "('.', 9)\n",
      "(':', 10)\n",
      "(';', 11)\n",
      "('?', 12)\n",
      "('A', 13)\n",
      "('Ah', 14)\n",
      "('Among', 15)\n",
      "('And', 16)\n",
      "('Are', 17)\n",
      "('Arrt', 18)\n",
      "('As', 19)\n",
      "('At', 20)\n",
      "('Be', 21)\n",
      "('Begin', 22)\n",
      "('Burlington', 23)\n",
      "('But', 24)\n",
      "('By', 25)\n",
      "('Carlo', 26)\n",
      "('Chicago', 27)\n",
      "('Claude', 28)\n",
      "('Come', 29)\n",
      "('Croft', 30)\n",
      "('Destroyed', 31)\n",
      "('Devonshire', 32)\n",
      "('Don', 33)\n",
      "('Dubarry', 34)\n",
      "('Emperors', 35)\n",
      "('Florence', 36)\n",
      "('For', 37)\n",
      "('Gallery', 38)\n",
      "('Gideon', 39)\n",
      "('Gisburn', 40)\n",
      "('Gisburns', 41)\n",
      "('Grafton', 42)\n",
      "('Greek', 43)\n",
      "('Grindle', 44)\n",
      "('Grindles', 45)\n",
      "('HAD', 46)\n",
      "('Had', 47)\n",
      "('Hang', 48)\n",
      "('Has', 49)\n",
      "('He', 50)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(vocab.items()):\n",
    "    print(item)\n",
    "    if i >= 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1dc314-351b-476a-9459-0ec9ddc29b19",
   "metadata": {},
   "source": [
    "- Below, we illustrate the tokenization of a short sample text using a small vocabulary:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67407a9f-0202-4e7c-9ed7-1b3154191ebc",
   "metadata": {},
   "source": [
    "<img src=\"figures/05.png\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e569647-2589-4c9d-9a5c-aef1c88a0a9a",
   "metadata": {},
   "source": [
    "- Let's now put it all together into a tokenizer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f531bf46-7c25-4ef8-bff8-0d27518676d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [\n",
    "            item.strip() for item in preprocessed if item.strip()\n",
    "        ]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        # Replace spaces before the specified punctuations\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee7a1e5-b54f-4ca1-87ef-3d663c4ee1e7",
   "metadata": {},
   "source": [
    "- The `encode` function turns text into token IDs\n",
    "- The `decode` function turns token IDs back into text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc21d347-ec03-4823-b3d4-9d686e495617",
   "metadata": {},
   "source": [
    "<img src=\"figures/06.png\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2950a94-6b0d-474e-8ed0-66d0c3c1a95c",
   "metadata": {},
   "source": [
    "- We can use the tokenizer to encode (that is, tokenize) texts into integers\n",
    "- These integers can then be embedded (later) as input of/for the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "647364ec-7995-4654-9b4a-7607ccf5f1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 58, 4, 852, 990, 604, 535, 748, 7, 1128, 598, 7, 3, 69, 9, 40, 853, 1110, 756, 795, 9]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "\n",
    "text = \"\"\"\"It's the last he painted, you know,\" \n",
    "           Mrs. Gisburn said with pardonable pride.\"\"\"\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3201706e-a487-4b60-b99d-5765865f29a0",
   "metadata": {},
   "source": [
    "- We can decode the integers back into text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01d8c8fb-432d-4a49-b332-99f23b233746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54f6aa8b-9827-412e-9035-e827296ab0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4ba34b-170f-4e71-939b-77aabb776f14",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# 2.3 BytePair encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2309494c-79cf-4a2d-bc28-a94d602f050e",
   "metadata": {},
   "source": [
    "- GPT-2 used BytePair encoding (BPE) as its tokenizer\n",
    "- it allows the model to break down words that aren't in its predefined vocabulary into smaller subword units or even individual characters, enabling it to handle out-of-vocabulary words\n",
    "- For instance, if GPT-2's vocabulary doesn't have the word \"unfamiliarword,\" it might tokenize it as [\"unfam\", \"iliar\", \"word\"] or some other subword breakdown, depending on its trained BPE merges\n",
    "- The original BPE tokenizer can be found here: [https://github.com/openai/gpt-2/blob/master/src/encoder.py](https://github.com/openai/gpt-2/blob/master/src/encoder.py)\n",
    "- In this lecture, we are using the BPE tokenizer from OpenAI's open-source [tiktoken](https://github.com/openai/tiktoken) library, which implements its core algorithms in Rust to improve computational performance\n",
    "- (Based on an analysis [here](https://github.com/rasbt/LLMs-from-scratch/blob/main/ch02/02_bonus_bytepair-encoder/compare-bpe-tiktoken.ipynb), I found that `tiktoken` is approx. 3x faster than the original tokenizer and 6x faster than an equivalent tokenizer in Hugging Face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede1d41f-934b-4bf4-8184-54394a257a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48967a77-7d17-42bf-9e92-fc619d63a59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version: 0.7.0\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import tiktoken\n",
    "\n",
    "print(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ad3312f-a5f7-4efc-9d7d-8ea09d7b5128",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ff2cd85-7cfb-4325-b390-219938589428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n"
     ]
    }
   ],
   "source": [
    "text = (\n",
    "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
    "     \"of someunknownPlace.\"\n",
    ")\n",
    "\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d26a48bb-f82e-41a8-a955-a1c9cf9d50ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"
     ]
    }
   ],
   "source": [
    "strings = tokenizer.decode(integers)\n",
    "\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c2e7b4-6a22-42aa-8e4d-901f06378d4a",
   "metadata": {},
   "source": [
    "- BPE tokenizers break down unknown words into subwords and individual characters:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c082d41f-33d7-4827-97d8-993d5a84bb3c",
   "metadata": {},
   "source": [
    "<img src=\"figures/07.png\" width=\"700px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beb27ee-1156-457c-839e-eebb48d94d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.encode(\"Akwirw ier\", allowed_special={\"<|endoftext|>\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbd7c0d-70f8-4386-a114-907e96c950b0",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# 2.4 Data sampling with a sliding window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509d9826-6384-462e-aa8a-a7c73cd6aad0",
   "metadata": {},
   "source": [
    "- Above, we took care of the tokenization (converting text into word tokens represented as token ID numbers)\n",
    "- Now, let's talk about how we create the data loading for LLMs\n",
    "- We train LLMs to generate one word at a time, so we want to prepare the training data accordingly where the next word in a sequence represents the target to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fb44f4-0c43-4a6a-9c2f-9cf31452354c",
   "metadata": {},
   "source": [
    "<img src=\"figures/08.png\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9a3d50-885b-49bc-b791-9f5cc8bc7b7c",
   "metadata": {},
   "source": [
    "- For this, we use a sliding window approach, changing the position by +1:\n",
    "\n",
    "<img src=\"figures/09.png\" width=\"900px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b006212f-de45-468d-bdee-5806216d1679",
   "metadata": {},
   "source": [
    "- Note that in practice it's best to set the stride equal to the context length so that we don't have overlaps between the inputs (the targets are still shifted by +1 always)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb467e0-bdcd-4dda-b9b0-a738c5d33ac3",
   "metadata": {},
   "source": [
    "<img src=\"figures/10.png\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb55f51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from supplementary import create_dataloader_v1\n",
    "\n",
    "\n",
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc671fb-6945-4594-b33f-8b462a69720d",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# Exercise: Prepare your own favorite text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb20de71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from supplementary import create_dataloader_v1\n",
    "\n",
    "example_text = \"\"\"Just rewatching The Mentalist and this scene had me in stitches. Jane is in prison and tries to get Cho to bring a person of interest to jail so he can speak to him. Cho, of course, refuses so Jane rings the person from Jail...\n",
    "\n",
    "[on the phone] \n",
    "\n",
    "Patrick Jane : Agent Rigsby, CBI. I'm on my way to your location. I have a couple of questions I wanted to ask you first. Discreetly.\n",
    "\n",
    "Roddy Gerber : Yeah?\n",
    "\n",
    "Patrick Jane : I've heard from a couple of reliable sources that you and Kirby Hines were having an affair. Some kind of sexual relationship.\n",
    "\n",
    "Roddy Gerber : That's a damn lie!\n",
    "\n",
    "Patrick Jane : Are you sure, Roddy? Lying to a CBI agent is a very serious offense.\n",
    "\n",
    "Roddy Gerber : I was in the Marine Corps!\n",
    "\n",
    "Patrick Jane : Oh really? Well, that says it all. I'm ex-Army. Marine Corps suck eggs! But hey, no point in arguing over the phone. We'll sort this out when I get to your location. Semper Fi, sissy-britches!\n",
    "\n",
    "(Rigsby got punched in the face, the moment he arrived and Roddy Gerber ended up in the prison shortly after)\"\"\"\n",
    "\n",
    "tokens = tokenizer.encode(example_text, allowed_special={\"<|endoftext|>\"})\n",
    "dataloader = create_dataloader_v1(example_text, batch_size=1, stride=4, max_length=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33b31b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 5703,   302, 50042,   383, 21235,   396,   290,   428]]), tensor([[  302, 50042,   383, 21235,   396,   290,   428,  3715]])]\n",
      "[tensor([[21235,   396,   290,   428,  3715,   550,   502,   287]]), tensor([[  396,   290,   428,  3715,   550,   502,   287, 28096]])]\n",
      "[tensor([[ 3715,   550,   502,   287, 28096,    13, 12091,   318]]), tensor([[  550,   502,   287, 28096,    13, 12091,   318,   287]])]\n",
      "[tensor([[28096,    13, 12091,   318,   287,  3770,   290,  8404]]), tensor([[   13, 12091,   318,   287,  3770,   290,  8404,   284]])]\n",
      "[tensor([[  287,  3770,   290,  8404,   284,   651, 10031,   284]]), tensor([[ 3770,   290,  8404,   284,   651, 10031,   284,  2222]])]\n",
      "[tensor([[  284,   651, 10031,   284,  2222,   257,  1048,   286]]), tensor([[  651, 10031,   284,  2222,   257,  1048,   286,  1393]])]\n",
      "[tensor([[2222,  257, 1048,  286, 1393,  284, 7356,  523]]), tensor([[ 257, 1048,  286, 1393,  284, 7356,  523,  339]])]\n",
      "[tensor([[1393,  284, 7356,  523,  339,  460, 2740,  284]]), tensor([[ 284, 7356,  523,  339,  460, 2740,  284,  683]])]\n",
      "[tensor([[  339,   460,  2740,   284,   683,    13, 10031,    11]]), tensor([[  460,  2740,   284,   683,    13, 10031,    11,   286]])]\n",
      "[tensor([[  683,    13, 10031,    11,   286,  1781,    11, 17567]]), tensor([[   13, 10031,    11,   286,  1781,    11, 17567,   523]])]\n",
      "[tensor([[  286,  1781,    11, 17567,   523, 12091, 13917,   262]]), tensor([[ 1781,    11, 17567,   523, 12091, 13917,   262,  1048]])]\n",
      "[tensor([[  523, 12091, 13917,   262,  1048,   422, 25715,   986]]), tensor([[12091, 13917,   262,  1048,   422, 25715,   986,   198]])]\n",
      "[tensor([[ 1048,   422, 25715,   986,   198,   198,    58,   261]]), tensor([[  422, 25715,   986,   198,   198,    58,   261,   262]])]\n",
      "[tensor([[ 198,  198,   58,  261,  262, 3072,   60,  220]]), tensor([[ 198,   58,  261,  262, 3072,   60,  220,  198]])]\n",
      "[tensor([[  262,  3072,    60,   220,   198,   198, 32718, 12091]]), tensor([[ 3072,    60,   220,   198,   198, 32718, 12091,  1058]])]\n",
      "[tensor([[  198,   198, 32718, 12091,  1058, 15906,   371,  9235]]), tensor([[  198, 32718, 12091,  1058, 15906,   371,  9235,  1525]])]\n",
      "[tensor([[ 1058, 15906,   371,  9235,  1525,    11, 47970,    13]]), tensor([[15906,   371,  9235,  1525,    11, 47970,    13,   314]])]\n",
      "[tensor([[ 1525,    11, 47970,    13,   314,  1101,   319,   616]]), tensor([[   11, 47970,    13,   314,  1101,   319,   616,   835]])]\n",
      "[tensor([[ 314, 1101,  319,  616,  835,  284,  534, 4067]]), tensor([[1101,  319,  616,  835,  284,  534, 4067,   13]])]\n",
      "[tensor([[ 835,  284,  534, 4067,   13,  314,  423,  257]]), tensor([[ 284,  534, 4067,   13,  314,  423,  257, 3155]])]\n",
      "[tensor([[  13,  314,  423,  257, 3155,  286, 2683,  314]]), tensor([[ 314,  423,  257, 3155,  286, 2683,  314, 2227]])]\n",
      "[tensor([[3155,  286, 2683,  314, 2227,  284, 1265,  345]]), tensor([[ 286, 2683,  314, 2227,  284, 1265,  345,  717]])]\n",
      "[tensor([[2227,  284, 1265,  345,  717,   13, 8444, 2871]]), tensor([[ 284, 1265,  345,  717,   13, 8444, 2871,  306]])]\n",
      "[tensor([[ 717,   13, 8444, 2871,  306,   13,  198,  198]]), tensor([[  13, 8444, 2871,  306,   13,  198,  198,   49]])]\n",
      "[tensor([[  306,    13,   198,   198,    49, 38553, 13573,   527]]), tensor([[   13,   198,   198,    49, 38553, 13573,   527,  1058]])]\n",
      "[tensor([[   49, 38553, 13573,   527,  1058,  9425,    30,   198]]), tensor([[38553, 13573,   527,  1058,  9425,    30,   198,   198]])]\n",
      "[tensor([[ 1058,  9425,    30,   198,   198, 32718, 12091,  1058]]), tensor([[ 9425,    30,   198,   198, 32718, 12091,  1058,   314]])]\n",
      "[tensor([[  198, 32718, 12091,  1058,   314,  1053,  2982,   422]]), tensor([[32718, 12091,  1058,   314,  1053,  2982,   422,   257]])]\n",
      "[tensor([[ 314, 1053, 2982,  422,  257, 3155,  286, 9314]]), tensor([[1053, 2982,  422,  257, 3155,  286, 9314, 4237]])]\n",
      "[tensor([[ 257, 3155,  286, 9314, 4237,  326,  345,  290]]), tensor([[ 3155,   286,  9314,  4237,   326,   345,   290, 23965]])]\n",
      "[tensor([[ 4237,   326,   345,   290, 23965,   367,  1127,   547]]), tensor([[  326,   345,   290, 23965,   367,  1127,   547,  1719]])]\n",
      "[tensor([[23965,   367,  1127,   547,  1719,   281, 14669,    13]]), tensor([[  367,  1127,   547,  1719,   281, 14669,    13,  2773]])]\n",
      "[tensor([[ 1719,   281, 14669,    13,  2773,  1611,   286,  3206]]), tensor([[  281, 14669,    13,  2773,  1611,   286,  3206,  2776]])]\n",
      "[tensor([[2773, 1611,  286, 3206, 2776,   13,  198,  198]]), tensor([[1611,  286, 3206, 2776,   13,  198,  198,   49]])]\n",
      "[tensor([[ 2776,    13,   198,   198,    49, 38553, 13573,   527]]), tensor([[   13,   198,   198,    49, 38553, 13573,   527,  1058]])]\n",
      "[tensor([[   49, 38553, 13573,   527,  1058,  1320,   338,   257]]), tensor([[38553, 13573,   527,  1058,  1320,   338,   257, 12270]])]\n",
      "[tensor([[ 1058,  1320,   338,   257, 12270,  6486,     0,   198]]), tensor([[ 1320,   338,   257, 12270,  6486,     0,   198,   198]])]\n",
      "[tensor([[12270,  6486,     0,   198,   198, 32718, 12091,  1058]]), tensor([[ 6486,     0,   198,   198, 32718, 12091,  1058,  4231]])]\n",
      "[tensor([[  198, 32718, 12091,  1058,  4231,   345,  1654,    11]]), tensor([[32718, 12091,  1058,  4231,   345,  1654,    11,   371]])]\n",
      "[tensor([[ 4231,   345,  1654,    11,   371, 38553,    30,   406]]), tensor([[  345,  1654,    11,   371, 38553,    30,   406,  1112]])]\n",
      "[tensor([[  371, 38553,    30,   406,  1112,   284,   257, 47970]]), tensor([[38553,    30,   406,  1112,   284,   257, 47970,  5797]])]\n",
      "[tensor([[ 1112,   284,   257, 47970,  5797,   318,   257,   845]]), tensor([[  284,   257, 47970,  5797,   318,   257,   845,  2726]])]\n",
      "[tensor([[5797,  318,  257,  845, 2726, 6907,   13,  198]]), tensor([[ 318,  257,  845, 2726, 6907,   13,  198,  198]])]\n",
      "[tensor([[ 2726,  6907,    13,   198,   198,    49, 38553, 13573]]), tensor([[ 6907,    13,   198,   198,    49, 38553, 13573,   527]])]\n",
      "[tensor([[  198,    49, 38553, 13573,   527,  1058,   314,   373]]), tensor([[   49, 38553, 13573,   527,  1058,   314,   373,   287]])]\n",
      "[tensor([[  527,  1058,   314,   373,   287,   262, 11000, 12778]]), tensor([[ 1058,   314,   373,   287,   262, 11000, 12778,     0]])]\n",
      "[tensor([[  287,   262, 11000, 12778,     0,   198,   198, 32718]]), tensor([[  262, 11000, 12778,     0,   198,   198, 32718, 12091]])]\n",
      "[tensor([[    0,   198,   198, 32718, 12091,  1058,  3966,  1107]]), tensor([[  198,   198, 32718, 12091,  1058,  3966,  1107,    30]])]\n",
      "[tensor([[12091,  1058,  3966,  1107,    30,  3894,    11,   326]]), tensor([[1058, 3966, 1107,   30, 3894,   11,  326, 1139]])]\n",
      "[tensor([[  30, 3894,   11,  326, 1139,  340,  477,   13]]), tensor([[3894,   11,  326, 1139,  340,  477,   13,  314]])]\n",
      "[tensor([[1139,  340,  477,   13,  314, 1101,  409,   12]]), tensor([[  340,   477,    13,   314,  1101,   409,    12, 45272]])]\n",
      "[tensor([[  314,  1101,   409,    12, 45272,    13, 11000, 12778]]), tensor([[ 1101,   409,    12, 45272,    13, 11000, 12778, 10110]])]\n",
      "[tensor([[45272,    13, 11000, 12778, 10110,  9653,     0,   887]]), tensor([[   13, 11000, 12778, 10110,  9653,     0,   887, 17207]])]\n",
      "[tensor([[10110,  9653,     0,   887, 17207,    11,   645,   966]]), tensor([[ 9653,     0,   887, 17207,    11,   645,   966,   287]])]\n",
      "[tensor([[17207,    11,   645,   966,   287, 11810,   625,   262]]), tensor([[   11,   645,   966,   287, 11810,   625,   262,  3072]])]\n",
      "[tensor([[  287, 11810,   625,   262,  3072,    13,   775,  1183]]), tensor([[11810,   625,   262,  3072,    13,   775,  1183,  3297]])]\n",
      "[tensor([[3072,   13,  775, 1183, 3297,  428,  503,  618]]), tensor([[  13,  775, 1183, 3297,  428,  503,  618,  314]])]\n",
      "[tensor([[3297,  428,  503,  618,  314,  651,  284,  534]]), tensor([[ 428,  503,  618,  314,  651,  284,  534, 4067]])]\n",
      "[tensor([[  314,   651,   284,   534,  4067,    13, 12449,   525]]), tensor([[  651,   284,   534,  4067,    13, 12449,   525, 23238]])]\n",
      "[tensor([[ 4067,    13, 12449,   525, 23238,    11,   264, 36419]]), tensor([[   13, 12449,   525, 23238,    11,   264, 36419,    12]])]\n",
      "[tensor([[23238,    11,   264, 36419,    12,    65,   799,  2052]]), tensor([[   11,   264, 36419,    12,    65,   799,  2052,     0]])]\n",
      "[tensor([[  12,   65,  799, 2052,    0,  198,  198,    7]]), tensor([[  65,  799, 2052,    0,  198,  198,    7,   49]])]\n",
      "[tensor([[   0,  198,  198,    7,   49, 9235, 1525, 1392]]), tensor([[  198,   198,     7,    49,  9235,  1525,  1392, 25436]])]\n",
      "[tensor([[   49,  9235,  1525,  1392, 25436,   287,   262,  1986]]), tensor([[ 9235,  1525,  1392, 25436,   287,   262,  1986,    11]])]\n",
      "[tensor([[25436,   287,   262,  1986,    11,   262,  2589,   339]]), tensor([[ 287,  262, 1986,   11,  262, 2589,  339, 5284]])]\n",
      "[tensor([[   11,   262,  2589,   339,  5284,   290,   371, 38553]]), tensor([[  262,  2589,   339,  5284,   290,   371, 38553, 13573]])]\n",
      "[tensor([[ 5284,   290,   371, 38553, 13573,   527,  4444,   510]]), tensor([[  290,   371, 38553, 13573,   527,  4444,   510,   287]])]\n",
      "[tensor([[13573,   527,  4444,   510,   287,   262,  3770,  8972]]), tensor([[ 527, 4444,  510,  287,  262, 3770, 8972,  706]])]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for batch in dataloader:\n",
    "    print(batch)\n",
    "    if i == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfcbeb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
